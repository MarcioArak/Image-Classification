{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "debf680e-a05c-487c-9926-0b37f84e19d8",
   "metadata": {},
   "source": [
    "# Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb45dff1-a47a-4883-ba67-8855c1fcacc0",
   "metadata": {
    "tags": []
   },
   "source": [
    "The data was collected from various search engines, and stored in a file called 'data' where we store the images in folders with their corresponding label. We start by setting up our GPU for usage by downloading and configuring the appropriate software. We remove any images that do not have an image extension in the code because some images downloaded are not appropriate image datasets. Data is configure for better processing when training the model. A sequential model is used and tested with different Dense and 2DConvolutional layers.  \n",
    "\n",
    "One thing to note was that when training my model the pictures were being trained in RGB, but when using OpenCV to test my model my pictures where going in as BGR which lower the accuracy by 30%. After fixing this problem model's classification increased to about 60-70%.\n",
    "When I tried to recreate the layers for the VGG16 model (a model that has won awards on image classificaiton) the accuracy surprisingly dropped again to about 30%. Leading me to believe that the model is too big for my datasets since it's only about 250 images per category and the model was made to classify 1000s of categories filled with 1000s of pictures. So instead I research that the recommended amount of images is around 1000 per category. And after downloading and using data augmentation to attain more data the model's accuracy increased to about 80%.\n",
    "\n",
    "After getting a sufficient accuracy (80% was ok with me because I used mostly of edges cases or harder to identify pictures to really test my model) categorizing 3 sports balls (basketballs, soccer balls and volleyballs) I added more labels of balls to see if my model would hold up or needed more tuning. I also added a 'star' label to see if the model was generalizing well between the shape of the ball and the shape of a star. When adding new categories (bowling balls, tennis balls ans stars) the model did not performed so well, so more tuning was needed to accomodate for the new difference in data. Although the model was pretty good at classifying stars sometimes it would confused stars with tennisballs and visa versa. This tells me that color is a pretty big factor in categorizing images and this is especially hard when categorizing sports balls because some balls are filled with colors that cover up the details that set it apart from other balls.\n",
    "\n",
    "To clean some of my data for example I deleted images where the 3 holes of the bowling ball was missing because without it it just looked like it could be any rubber ball. And images that I consider edge cases that the model kept getting wrong were augmented and added to the training data to see if the model could pick up on similarities of the pictures by adding its augmented images and not the image itself. With this the model performed to about 84% accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9324dd6c-f926-472d-bcb3-79e310482593",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Challenges"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc523d8-047d-4c9f-8ef0-86b14d7221da",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 1. Splitting Data\n",
    "When splitting data as shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373cf518-1cc5-4377-98db-ce6be38ed025",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = tf.keras.utils.image_dataset_from_directory(\n",
    "    os.path.join(data_dir, 'training'), \n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=123,\n",
    "    batch_size = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f92f509-bf3a-49d7-ab30-09c290f2078e",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_set = tf.keras.utils.image_dataset_from_directory(\n",
    "    os.path.join(data_dir, 'training'), \n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=123,\n",
    "    batch_size = 64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0734757b-72e5-4067-9424-e72b26fdc594",
   "metadata": {},
   "source": [
    "The accuracy of the model decreased by a lot. When training the model the validation part would be stuck at 80% accuracy when the training accuracy was close to 98% meaning my the model was overfitting.  \n",
    "But when I split my data like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3bf684-331b-4363-8702-5b53ce1acc9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set = tf.keras.utils.image_dataset_from_directory(\n",
    "    os.path.join(data_dir, 'training'), \n",
    "    batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033578c4-4796-4f06-af2a-6f06e8edf65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "training = data_set.take(int(len(data_set)*.8))\n",
    "validation = data_set.skip(int(len(data_set)*.8)).take(int(len(data_set)*.2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b9f167e-2124-438a-a0af-2e5f50217895",
   "metadata": {},
   "source": [
    "The model training and validation are pretty close together in accuracy.  \n",
    "But caching and prefetching the trainig and validation data separately would give me the same problem of overfitting, so the code below must be done before splitting the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e4c1c2-a218-415e-ad26-a7e9d3be7fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "data_set = data_set.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b81bd8-5417-4c04-840b-0a65c306644a",
   "metadata": {},
   "source": [
    "Have not figured out why this happens yet.. :("
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2fff002-4ef8-4d4e-baa8-ecd63621c228",
   "metadata": {},
   "source": [
    "### 2. Modeling\n",
    "These are the models that worked best for me when testing different number and combination of categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d5222d-b7de-4d61-9ac6-09b0c3930c2d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Best model for 3 categories\n",
    "model.add(Conv2D(16, (3, 3), 1, activation='relu', input_shape=(256, 256, 3)))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), 1, activation='relu'))\n",
    "model.add(Conv2D(32, (3, 3), 1, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "\n",
    "model.add(Conv2D(16, (3, 3), 1, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(len(class_names)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4273067e-1ac3-4a5a-bba2-aa3220fe6b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best model for 6 categories\n",
    "model.add(Conv2D(16, (3, 3), 1, activation='relu', input_shape=(256, 256, 3)))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "\n",
    "model.add(Conv2D(16, (3, 3), 1, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), 1, activation='relu'))\n",
    "model.add(Conv2D(32, (3, 3), 1, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), 1, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(len(class_names)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28223f1e-adea-400c-a9d1-6160a40ee877",
   "metadata": {},
   "source": [
    "### 3. Cross Validation\n",
    "I coded a K-fold cross validation that would work with my code because of the way that my data splits, since my images and labels are in the same array.  \n",
    "My challenge with this ties with my splitting challenge. Because I split the data the following way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869dcc56-bbca-45bf-9141-5b98f360d306",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = data.take(first_seg)\n",
    "test = data.skip(first_seg).take(test_seg)\n",
    "t2 = data.skip(first_seg + test_seg).take(second_seg)\n",
    "train = t1.concatenate(t2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911fa913-05ff-4486-af62-1a3b4941c4f6",
   "metadata": {},
   "source": [
    "It would give better results when evaluating the model than the actual trained model if I split the data using keras.utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6953aa6-d170-4908-85c7-408fcf59ae29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
